#!/usr/bin/env python3
"""
æ¯æ—¥ç®€æŠ¥ç”Ÿæˆå™¨
- æŠ“å–RSSæ–‡ç« 
- Claude APIæ‘˜è¦
- ç”ŸæˆShadcn UIé£æ ¼çš„HTML
"""

import sys
import json
import os
import ssl
from datetime import datetime
from pathlib import Path
from urllib.request import urlopen, Request
from urllib.error import URLError
import xml.etree.ElementTree as ET
import anthropic

# ç¦ç”¨SSLéªŒè¯
ssl._create_default_https_context = ssl._create_unverified_context

# é…ç½®
OPML_FILE = Path(__file__).parent.parent / "sources" / "karpathy-rss.opml"
OUTPUT_DIR = Path(__file__).parent.parent / "data" / "briefing"
MAX_SOURCES = int(sys.argv[1]) if len(sys.argv) > 1 else 3
MAX_ITEMS = 2  # æ¯ä¸ªæºå–2ç¯‡ï¼ˆæ§åˆ¶APIè°ƒç”¨æˆæœ¬ï¼‰

# Claude API
API_KEY = os.environ.get("ANTHROPIC_API_KEY")
if not API_KEY:
    print("âŒ è¯·è®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
    sys.exit(1)

client = anthropic.Anthropic(api_key=API_KEY)

HTML_TEMPLATE = """<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ¯æ—¥ç®€æŠ¥ - {date}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Noto Sans SC", sans-serif;
            background: #f8fafc;
            color: #1e293b;
            line-height: 1.6;
            padding: 2rem 1rem;
        }}
        .container {{
            max-width: 800px;
            margin: 0 auto;
        }}
        header {{
            text-align: center;
            margin-bottom: 2rem;
            padding-bottom: 1rem;
            border-bottom: 1px solid #e2e8f0;
        }}
        h1 {{
            font-size: 1.5rem;
            font-weight: 600;
            color: #0f172a;
            margin-bottom: 0.5rem;
        }}
        .date {{
            color: #64748b;
            font-size: 0.875rem;
        }}
        article {{
            background: white;
            border-radius: 0.75rem;
            padding: 1.5rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            transition: box-shadow 0.2s, transform 0.2s;
        }}
        article:hover {{
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            transform: translateY(-1px);
        }}
        .source {{
            font-size: 0.75rem;
            color: #64748b;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.5rem;
        }}
        h2 {{
            font-size: 1.125rem;
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #0f172a;
        }}
        h2 a {{
            color: inherit;
            text-decoration: none;
        }}
        h2 a:hover {{
            color: #3b82f6;
        }}
        .summary {{
            color: #475569;
            font-size: 0.9375rem;
            line-height: 1.7;
        }}
        .summary ul {{
            padding-left: 1.25rem;
            margin-top: 0.5rem;
        }}
        .summary li {{
            margin-bottom: 0.375rem;
        }}
        footer {{
            text-align: center;
            margin-top: 3rem;
            color: #94a3b8;
            font-size: 0.875rem;
        }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>æ¯æ—¥ç®€æŠ¥</h1>
            <p class="date">{date}</p>
        </header>
        {content}
        <footer>
            <p>ç”± Mino è‡ªåŠ¨ç”Ÿæˆ Â· Claude API é©±åŠ¨</p>
        </footer>
    </div>
</body>
</html>
"""

def fetch_rss(url: str) -> str:
    """æŠ“å–RSS feed"""
    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    with urlopen(req, timeout=10) as response:
        return response.read().decode('utf-8', errors='ignore')

def parse_rss(xml_content: str) -> list:
    """è§£æRSS/Atom feed"""
    items = []
    try:
        root = ET.fromstring(xml_content)
        namespaces = {'atom': 'http://www.w3.org/2005/Atom'}

        if root.tag == '{http://www.w3.org/2005/Atom}feed':
            for entry in root.findall('atom:entry', namespaces)[:MAX_ITEMS]:
                title = entry.find('atom:title', namespaces)
                link = entry.find('atom:link', namespaces)
                content = entry.find('atom:content', namespaces) or entry.find('atom:summary', namespaces)
                items.append({
                    'title': title.text if title is not None else '',
                    'link': link.get('href') if link is not None else '',
                    'content': content.text if content is not None else ''
                })
        else:
            for item in root.findall('.//item')[:MAX_ITEMS]:
                title = item.find('title')
                link = item.find('link')
                desc = item.find('description') or item.find('{http://purl.org/rss/1.0/modules/content/}encoded')
                items.append({
                    'title': title.text if title is not None else '',
                    'link': link.text if link is not None else '',
                    'content': desc.text if desc is not None else ''
                })
    except Exception as e:
        print(f"  âš ï¸ è§£æé”™è¯¯: {e}")
    return items

def summarize(article: dict, source_name: str) -> str:
    """ç”¨Claude APIç”Ÿæˆæ‘˜è¦"""
    try:
        # é™åˆ¶è¾“å…¥é•¿åº¦
        content = article.get('content', '')[:3000]
        if not content:
            content = article.get('title', '')

        prompt = f"""è¯·ç”¨ä¸­æ–‡ä¸ºè¿™ç¯‡æ–‡ç« ç”Ÿæˆ3ç‚¹æ‘˜è¦ï¼Œæ¯ç‚¹ä¸è¶…è¿‡30å­—ã€‚

æ ‡é¢˜ï¼š{article['title']}
æ¥æºï¼š{source_name}
å†…å®¹ï¼š{content}

è¿”å›æ ¼å¼ï¼ˆç›´æ¥è¿”å›JSONï¼‰ï¼š
{{"points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]}}"""

        message = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=500,
            temperature=0.3,
            messages=[{"role": "user", "content": prompt}]
        )

        import re
        content = message.content[0].text
        # æå–JSON
        match = re.search(r'\{.*\}', content, re.DOTALL)
        if match:
            data = json.loads(match.group())
            points = data.get('points', [])
            return '<ul>' + ''.join(f'<li>{p}</li>' for p in points) + '</ul>'
        return f'<p>{content[:200]}...</p>'
    except Exception as e:
        print(f"  âš ï¸ æ‘˜è¦å¤±è´¥: {e}")
        return '<p>æ‘˜è¦ç”Ÿæˆå¤±è´¥</p>'

def extract_opml_urls(opml_path: Path) -> list:
    """ä»OPMLæå–RSSæº"""
    tree = ET.parse(opml_path)
    root = tree.getroot()
    return [outline.get('xmlUrl') for outline in root.findall('.//outline') if outline.get('xmlUrl')]

def main():
    print("ğŸ“° ç”Ÿæˆæ¯æ—¥ç®€æŠ¥...")
    print(f"æŠ“å–å‰ {MAX_SOURCES} ä¸ªRSSæºï¼Œæ¯ä¸ªæº {MAX_ITEMS} ç¯‡æ–‡ç« \n")

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    today = datetime.now().strftime('%Y-%m-%d')

    rss_urls = extract_opml_urls(OPML_FILE)
    articles_html = []

    for i, url in enumerate(rss_urls[:MAX_SOURCES], 1):
        print(f"[{i}/{MAX_SOURCES}] å¤„ç†: {url}")

        try:
            xml = fetch_rss(url)
            items = parse_rss(xml)

            for item in items:
                if not item.get('title'):
                    continue

                print(f"  ğŸ“„ {item['title'][:50]}...")
                summary = summarize(item, url)

                articles_html.append(f"""
        <article>
            <div class="source">{url}</div>
            <h2><a href="{item['link']}" target="_blank">{item['title']}</a></h2>
            <div class="summary">{summary}</div>
        </article>""")

        except Exception as e:
            print(f"  âŒ é”™è¯¯: {e}")

    # ç”ŸæˆHTML
    html = HTML_TEMPLATE.format(
        date=today,
        content=''.join(articles_html)
    )

    output_file = OUTPUT_DIR / f"{today}.html"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(html)

    print(f"\nâœ… ç®€æŠ¥ç”Ÿæˆï¼š{output_file}")
    print(f"ğŸŒ åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŸ¥çœ‹æ•ˆæœ")

if __name__ == '__main__':
    main()
